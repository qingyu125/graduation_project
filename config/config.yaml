# 面向高效推理的要素抽取系统配置文件

# 项目基本信息
project:
  name: "DocRED关系抽取系统"
  version: "1.0.0"
  author: "MiniMax Agent"
  date: "2025-11-06"

# 数据路径配置
data:
  raw:
    docred_path: "./data/raw/docred_sample"  # 您的DocRED数据位置
    train_annotated: "train_annotated.json"
    rel_info: "rel_info.json"
  processed:
    train_path: "./data/processed/train.json"   # 处理后的训练数据
    val_path: "./data/processed/val.json"       # 处理后的验证数据
    test_path: "./data/processed/test.json"     # 处理后的测试数据
    training_data: "./data/processed/docred_training_data.json"  # 完整训练数据
    gui_data: "./data/processed/gui_data.json"  # GUI数据
    rel_info_path: "./data/processed/rel_info.json"  # 关系信息
  output:
    results_path: "./results"
    logs_path: "./experiments/logs"
    model_path: "./experiments/checkpoints"

# 模型配置
models:
  base:
    name: "codellama-7b"
    model_path: "codellama/CodeLlama-7b-Instruct-hf"
    device: "cuda"
    precision: "4bit"
    
  fine_tuned:
    checkpoint_path: "./experiments/checkpoints/best_model"
    lora_config:
      r: 8  # LoRA秩
      lora_alpha: 32
      target_modules: ["q_proj", "v_proj", "k_proj", "o_proj"]
      lora_dropout: 0.1
      bias: "none"

# 训练配置
training:
  batch_size: 4
  learning_rate: 2e-4
  num_epochs: 15
  warmup_steps: 100
  max_seq_length: 2048
  gradient_accumulation_steps: 4
  save_steps: 500
  eval_steps: 500
  early_stopping:
    patience: 3
    min_delta: 0.001

# 数据预处理配置
preprocessing:
  max_length: 512
  max_entities: 50
  max_relations: 100
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1

# 提示模板配置
prompt_templates:
  text2pseudocode:
    max_examples: 5
    temperature: 0.3
    top_p: 0.9
    max_new_tokens: 512

# 要素抽取配置
extraction:
  ast:
    max_depth: 10
    min_confidence: 0.7
  entity_types:
    - "PERSON"
    - "ORG"
    - "LOC"
    - "MISC"
    - "EVENT"
    - "TIME"

# 知识融合配置
knowledge_fusion:
  knowledge_graph:
    source: "wikidata"
    refresh_interval: 24  # 小时
  confidence_threshold: 0.8
  max_candidates: 10

# 推理配置
inference:
  lmulator:
    max_steps: 100
    timeout: 30
  validation:
    consistency_check: true
    contradiction_detection: true

# 评估指标
evaluation:
  metrics:
    - "entity_f1"
    - "relation_f1"
    - "accuracy"
    - "logical_consistency"
  thresholds:
    entity_f1_target: 0.75  # 目标F1值
    relation_f1_target: 0.70
    accuracy_target: 0.80

# GUI配置
gui:
  window_size: [1200, 800]
  theme: "light"
  font_size: 10
  max_text_length: 10000
  supported_models:
    - "BERT-base"
    - "CodeLlama-7B (未微调)"
    - "CodeLlama-7B (微调后)"

# 日志配置
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file_path: "./logs/system.log"
  max_size: "10MB"
  backup_count: 5

# 硬件配置
hardware:
  gpu_memory_threshold: 0.8
  batch_processing: true
  num_workers: 4
  pin_memory: true